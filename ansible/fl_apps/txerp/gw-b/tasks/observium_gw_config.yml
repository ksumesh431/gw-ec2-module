- name: Observium heartbeat cron setup block
  block:
    - name: Get IMDSv2 token
      uri:
        url: http://169.254.169.254/latest/api/token
        method: PUT
        headers:
          X-aws-ec2-metadata-token-ttl-seconds: "300"
        return_content: true
      register: imds_token

    - name: Get region
      uri:
        url: http://169.254.169.254/latest/dynamic/instance-identity/document
        method: GET
        headers:
          X-aws-ec2-metadata-token: "{{ imds_token.content }}"
        return_content: true
      register: iid_doc

    - name: Check if ObserviumHeartbeat.sh exists on old EC2 instance
      ansible.builtin.shell: |
        aws ssm send-command \
          --instance-ids "{{ final_vars.old_gw_b_instnace_id }}" \
          --document-name "AWS-RunShellScript" \
          --parameters 'commands=["cat /usr/local/bin/ObserviumHeartbeat.sh"]' \
          --region "{{ aws_region }}" \
          --output text \
          --query 'Command.CommandId'
      register: obs_command_id

    - name: Wait for 3 seconds before fetching SSM command output
      ansible.builtin.wait_for:
        timeout: 3

    - name: Get ObserviumHeartbeat.sh content from SSM
      ansible.builtin.shell: |
        aws ssm get-command-invocation \
          --command-id "{{ obs_command_id.stdout }}" \
          --instance-id "{{ final_vars.old_gw_b_instnace_id }}" \
          --region "{{ aws_region }}" \
          --output text \
          --query 'StandardOutputContent'
      register: obs_file_output
      retries: 10
      delay: 2
      until: obs_file_output.rc == 0

    - name: Check if file was found
      ansible.builtin.debug:
        msg: "File not found on instance {{ final_vars.old_gw_b_instnace_id }}"
      when: obs_file_output.stdout == ""

    - name: Copy ObserviumHeartbeat.sh to localhost
      ansible.builtin.copy:
        content: "{{ obs_file_output.stdout }}"
        dest: /usr/local/bin/ObserviumHeartbeat.sh
        mode: "0755"
      when: obs_file_output.stdout != ""

    - name: Set cron job for ObserviumHeartbeat.sh
      ansible.builtin.cron:
        name: "Observium Heartbeat"
        job: "/usr/local/bin/ObserviumHeartbeat.sh"
        minute: "*/5"
      when: obs_file_output.stdout != ""




- name: Observium migration (old -> new) via SSM + local restore
  block:
    - name: Assert required variables are present
      ansible.builtin.assert:
        that:
          - aws_region is defined
          - final_vars.old_gw_b_instnace_id is defined
          - observium_s3_bucket is defined
          - observium_s3_prefix is defined
          - observium_migration_tag is defined
          - observium_base is defined
          - web_user is defined
          - web_group is defined

    - name: Ensure tools present on new instance
      ansible.builtin.package:
        name:
          - awscli
          - tar
          - gzip
        state: present
      become: true

    - name: Check if dump exists in S3
      ansible.builtin.shell: |
        aws s3api head-object \
          --bucket "{{ observium_s3_bucket }}" \
          --key "{{ s3_key_dump }}"
      register: _s3_dump_head
      changed_when: false
      failed_when: false

    - name: Check if RRD tar exists in S3
      ansible.builtin.shell: |
        aws s3api head-object \
          --bucket "{{ observium_s3_bucket }}" \
          --key "{{ s3_key_rrd }}"
      register: _s3_rrd_head
      changed_when: false
      failed_when: false

    - name: Decide if SSM dump/upload is needed
      ansible.builtin.set_fact:
        _need_ssm_dump: >-
          {{ (_s3_dump_head.rc != 0) or (_s3_rrd_head.rc != 0) }}

    - name: Build old-instance migration script (SSM)
      ansible.builtin.set_fact:
        old_migration_script: |
          #!/bin/bash
          set -Eeuo pipefail

          # Add logging and error handling
          exec 2>&1

          BASE="{{ observium_base }}"
          OUT="$BASE/migrate/{{ observium_migration_tag }}"
          S3="{{ s3_uri_base }}"
          mkdir -p "$OUT"

          echo "Script started at $(date)"
          echo "Running as user: $(whoami)"
          echo "Current directory: $(pwd)"

          LOG="$OUT/ssm-migration.log"
          exec > >(tee -a "$LOG") 2>&1

          echo "[OLD] Preparing dump to $OUT and upload to $S3"

          # Ensure tools
          if ! command -v mysqldump >/dev/null 2>&1; then
            if command -v apt-get >/dev/null 2>&1; then
              apt-get update -y && apt-get install -y mariadb-client || true
            elif command -v yum >/dev/null 2>&1; then
              yum install -y mariadb || true
            elif command -v dnf >/dev/null 2>&1; then
              dnf install -y mariadb || true
            fi
          fi
          if ! command -v aws >/dev/null 2>&1; then
            if command -v apt-get >/dev/null 2>&1; then
              apt-get update -y && apt-get install -y awscli || true
            elif command -v yum >/dev/null 2>&1; then
              yum install -y awscli || true
            elif command -v dnf >/dev/null 2>&1; then
              dnf install -y awscli || true
            fi
          fi

          # DB dump (skip if already exists locally)
          if [ ! -s "$OUT/observium-dump.sql" ]; then
            echo "[OLD] Creating DB dump..."
            MYSQL_PWD='{{ observium_db_pass_old }}' \
            mysqldump -u '{{ observium_db_user_old }}' \
              '{{ observium_db_name_old }}' \
              --no-tablespaces --single-transaction \
              --add-drop-table --extended-insert \
              > "$OUT/observium-dump.sql"
          else
            echo "[OLD] Local DB dump exists, skipping."
          fi

          # RRD archive (skip if already exists locally)
          if [ ! -s "$OUT/observium-rrd.tar.gz" ]; then
            echo "[OLD] Archiving RRD directory..."
            tar -C "$BASE" -zcf "$OUT/observium-rrd.tar.gz" rrd
          else
            echo "[OLD] Local RRD archive exists, skipping."
          fi

          # Save config.php (optional)
          if [ -f "$BASE/config.php" ] && [ ! -s "$OUT/config.php" ]; then
            cp -a "$BASE/config.php" "$OUT/config.php"
          fi

          # Upload to S3 only if missing
          if ! aws s3 ls "$S3/observium-dump.sql" >/dev/null 2>&1; then
            echo "[OLD] Uploading dump..."
            aws s3 cp "$OUT/observium-dump.sql" "$S3/"
          else
            echo "[OLD] Dump already in S3, skipping upload."
          fi

          if ! aws s3 ls "$S3/observium-rrd.tar.gz" >/dev/null 2>&1; then
            echo "[OLD] Uploading RRD archive..."
            aws s3 cp "$OUT/observium-rrd.tar.gz" "$S3/"
          else
            echo "[OLD] RRD already in S3, skipping upload."
          fi

          if [ -f "$OUT/config.php" ] && \
             ! aws s3 ls "$S3/config.php" >/dev/null 2>&1; then
            echo "[OLD] Uploading config.php..."
            aws s3 cp "$OUT/config.php" "$S3/"
          fi

          echo "[OLD] DONE"
      when: _need_ssm_dump

    - name: Trigger SSM on OLD instance to create/upload artifacts
      ansible.builtin.shell: |
        aws ssm send-command \
          --instance-ids "{{ final_vars.old_gw_b_instnace_id }}" \
          --document-name "AWS-RunShellScript" \
          --parameters '{{ {"commands": [ old_migration_script ] } | to_json }}' \
          --region "{{ aws_region }}" \
          --output text \
          --query 'Command.CommandId'
      register: _old_cmd_id
      when: _need_ssm_dump

    - name: Wait for OLD instance SSM command to finish
      ansible.builtin.shell: |
        aws ssm get-command-invocation \
          --command-id "{{ _old_cmd_id.stdout }}" \
          --instance-id "{{ final_vars.old_gw_b_instnace_id }}" \
          --region "{{ aws_region }}" \
          --output text \
          --query 'Status'
      register: _old_status
      retries: 180
      delay: 10
      until: _old_status.stdout in ['Success', 'Failed', 'Cancelled', 'TimedOut', 'DeliveryTimedOut']
      failed_when: _old_status.stdout in ['Cancelled', 'TimedOut', 'Failed', 'DeliveryTimedOut']
      changed_when: false
      when: _need_ssm_dump

    - name: Ensure local migration directory exists on new instance
      ansible.builtin.file:
        path: "{{ obs_mig_dir }}"
        state: directory
        mode: "0755"
      become: true

    - name: Download DB dump from S3 if not present
      ansible.builtin.shell: |
        aws s3 cp "{{ s3_uri_base }}/observium-dump.sql" \
          "{{ obs_mig_dir }}/"
      args:
        creates: "{{ obs_mig_dir }}/observium-dump.sql"
      changed_when: true
      become: true

    - name: Download RRD archive from S3 if not present
      ansible.builtin.shell: |
        aws s3 cp "{{ s3_uri_base }}/observium-rrd.tar.gz" \
          "{{ obs_mig_dir }}/"
      args:
        creates: "{{ obs_mig_dir }}/observium-rrd.tar.gz"
      changed_when: true
      become: true

    - name: Download config.php snapshot if present (best effort)
      ansible.builtin.shell: |
        aws s3 cp "{{ s3_uri_base }}/config.php" \
          "{{ obs_mig_dir }}/" || true
      changed_when: false
      become: true

    - name: Check if migration already applied
      ansible.builtin.stat:
        path: "{{ obs_mark }}"
      register: _mig_mark

    - name: Import DB and restore RRDs (one-time per tag)
      block:
        - name: Import Observium database from dump
          ansible.builtin.shell: |
            set -Eeuo pipefail
            BASE="{{ observium_base }}"
            OUT="{{ obs_mig_dir }}"
            DB="{{ observium_db_name_old }}"
            # Try building MYSQL command from config.php; fallback to socket/root
            MYSQL=(mysql)
            if ! "${MYSQL[@]}" -e 'SELECT 1' >/dev/null 2>&1; then
              if command -v php >/dev/null 2>&1 && \
                 [ -f "$BASE/config.php" ]; then
                DBU=$(php -r 'include "/opt/observium/config.php";
                  echo $config["db_user"];')
                DBP=$(php -r 'include "/opt/observium/config.php";
                  echo $config["db_pass"];')
                MYSQL=(mysql -u "$DBU" -p"$DBP")
              fi
            fi

            # Ensure database exists
            if ! "${MYSQL[@]}" -e "USE ${DB};" >/dev/null 2>&1; then
              "${MYSQL[@]}" -e "CREATE DATABASE IF NOT EXISTS ${DB}
                CHARACTER SET utf8 COLLATE utf8_general_ci;"
            fi

            # Drop all tables idempotently
            "${MYSQL[@]}" -N -e "
              SELECT CONCAT('DROP TABLE IF EXISTS \`', table_name, '\`;')
              FROM information_schema.tables
              WHERE table_schema='${DB}';
            " | "${MYSQL[@]}" "${DB}" || true

            # Import dump
            "${MYSQL[@]}" "${DB}" < "${OUT}/observium-dump.sql"
          args:
            executable: /bin/bash
          become: true

        - name: Restore RRD directory
          ansible.builtin.shell: |
            set -Eeuo pipefail
            BASE="{{ observium_base }}"
            OUT="{{ obs_mig_dir }}"
            TAG="{{ observium_migration_tag }}"

            if [ -d "$BASE/rrd" ] && [ ! -d "$BASE/rrd.bak.$TAG" ]; then
              mv "$BASE/rrd" "$BASE/rrd.bak.$TAG"
            fi

            tar -C "$BASE" -zxf "${OUT}/observium-rrd.tar.gz"

            chown -R "{{ web_user }}:{{ web_group }}" "$BASE/rrd" || true
          args:
            executable: /bin/bash
          become: true

        - name: Write migration done marker
          ansible.builtin.file:
            path: "{{ obs_mark }}"
            state: touch
            mode: "0644"
          become: true
      when: not _mig_mark.stat.exists
